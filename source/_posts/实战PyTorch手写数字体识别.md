---
title: 实战PyTorch手写数字体识别
tags:
  - PyTorch
  - Deep Learning
share: true
categories:
  - Deep Learning
  - CNN
reward: true
comment: true
top: 2
repo: 'sivanWu0222 | PyTorchDL'
date: 2019-09-29 19:47:51
description:
---

> 开始学习深度学习，想通过被誉为**深度学习"Hello World"的LeNet5**进行实践，奈何从网络架构看不懂到最后编码没看懂，到现在的恍然大悟，这里面有很多坑不实践只知道网络结构永远是不够的，在学习编码LeNet5的过程中，遇到了很多坑，从网上找资料，五音不全的，总感觉少了很多东西，所以自己索性就总结了自己LeNet5的经验以及一些坑

## 网络架构
![LeNet5网络结构图](./CNN.png)


输入的图片是 28*28*1 : **分别表示28像素的高，28像素的宽，1个颜色通道**

第一层：卷积层：卷积核大小为6*28*28, (6表示卷积核的通道数，决定了输出内容的个数，1表示卷积核的通道为1，28)
第二层：池化层
第三层：卷积层
第四层：池化层
第五层：全连接层
第六层：全连接层
第七层：全连接层



## 数据介绍
> 实战LeNet5架构的数据已经由大神Yann LeCun备好，只需要通过PyTorch下载并加载就可以


训练集：提供了60000张28*28像素的黑白图(说明颜色通道为1)，60000个标签
测试集：提供了10000张28*28像素的黑白图，10000个标签

![展示其中的一个数据](./数据图展示.png)

## 一些坑
1. ReLU() 与 torch.relu() 真的不一样，可别搞混，自己当时就是搞混，以为是一样的，卡了半天
2. 


## References
1. [网络架构完全不懂的参考](https://zhuanlan.zhihu.com/p/30117574) 缺点：后面的几层降解的不够全面
2. []()
[]()